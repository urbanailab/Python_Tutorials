{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LQRLLdqzXU_"
   },
   "source": [
    "# This script is to use images to predict mobility variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bb4VgVmHEkSF",
    "outputId": "c70fce45-1063-4375-e8a1-ae2f585dd0b3",
    "ExecuteTime": {
     "end_time": "2023-11-24T22:22:53.713390Z",
     "start_time": "2023-11-24T22:22:53.681579Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "# !pip install torch torchvision scikit-learn matplotlib pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ocEmUF_ntUI9",
    "ExecuteTime": {
     "end_time": "2023-11-24T22:24:15.653925Z",
     "start_time": "2023-11-24T22:24:15.646543Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.metrics import classification_report, mean_absolute_error, mean_squared_error, r2_score\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.init as init\n",
    "from CustomDataset import CustomDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "L_3zkytoawEQ",
    "ExecuteTime": {
     "end_time": "2023-11-24T22:24:18.012422Z",
     "start_time": "2023-11-24T22:24:18.006704Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pre-define some lists and loss\n",
    "loss_list = []\n",
    "residuals = []\n",
    "l1_loss = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "8ZHKAjZLaR3U",
    "ExecuteTime": {
     "end_time": "2023-11-24T22:24:18.368553Z",
     "start_time": "2023-11-24T22:24:18.365196Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the training loop function: trainloop\n",
    "def trainloop(train_loader):\n",
    "  # Set the number of training epochs\n",
    "  num_epoch = 10\n",
    "\n",
    "  # Iterate over each epoch\n",
    "  for epoch in range(num_epoch):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate over the batches in the training data\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "      # Extract inputs (images) and labels from the batch\n",
    "      inputs, labels = data\n",
    "\n",
    "      # Move inputs and labels to the device (GPU if available)\n",
    "      inputs = inputs.to(device).float()\n",
    "      labels = labels.to(device).float()\n",
    "\n",
    "      # Zero the gradients in the optimizer\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # Forward pass: compute model outputs\n",
    "      outputs = net(inputs)\n",
    "\n",
    "      # Calculate the L1 loss\n",
    "      loss = criterion(outputs, labels.view(-1, 1))\n",
    "\n",
    "      # Calculate L1 regularization term\n",
    "      l1_reg = 0.0\n",
    "      for param in net.parameters():\n",
    "        l1_reg += l1_loss(param, torch.zeros_like(param))\n",
    "\n",
    "      # Apply L1 regularization with a specified lambda\n",
    "      l1_lambda = 0.001\n",
    "      loss += l1_lambda * l1_reg\n",
    "\n",
    "      # Backpropagation: compute gradients and update model parameters\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Update running loss\n",
    "      running_loss += loss.item()\n",
    "\n",
    "      # Append current loss to loss_list for tracking\n",
    "      loss_list.append(loss.item())\n",
    "\n",
    "    # Print training statistics for the epoch\n",
    "    print(f\"Epoch {epoch + 1}/{num_epoch} - Loss: {running_loss / len(train_loader):.4f} \")\n",
    "\n",
    "  # Calculate and print R-squared on training data\n",
    "  predicted_train_labels = []\n",
    "  true_train_labels = []\n",
    "  with torch.no_grad():\n",
    "    for inputs, labels in train_loader:\n",
    "      inputs = inputs.to(device).float()\n",
    "      labels = labels.to(device).float()\n",
    "      outputs = net(inputs)\n",
    "      predicted_train_labels += outputs.squeeze().tolist()\n",
    "      true_train_labels += labels.tolist()\n",
    "  train_r2 = r2_score(true_train_labels, predicted_train_labels)\n",
    "  print(\"Train R-squared:\", train_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "BHNdwQtDa04Z",
    "outputId": "14385bad-bc98-4ccc-f938-5bf10818b58d",
    "ExecuteTime": {
     "end_time": "2023-11-24T22:49:36.659668Z",
     "start_time": "2023-11-24T22:34:51.975442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 0.8546 \n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/multiprocessing/connection.py\", line 360, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/multiprocessing/connection.py\", line 360, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/multiprocessing/queues.py\", line 250, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/multiprocessing/connection.py\", line 199, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/multiprocessing/connection.py\", line 410, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/multiprocessing/connection.py\", line 367, in _send\n",
      "    n = write(self._handle, buf)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/multiprocessing/connection.py\", line 360, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/multiprocessing/connection.py\", line 360, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/jh/p1jvq4k96b78klmgl3dq5jwc0000gn/T/ipykernel_25976/3772038928.py\", line 154, in <module>\n",
      "    trainloop(train_loader)\n",
      "  File \"/var/folders/jh/p1jvq4k96b78klmgl3dq5jwc0000gn/T/ipykernel_25976/2297517029.py\", line 23, in trainloop\n",
      "    outputs = net(inputs)\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/jh/p1jvq4k96b78klmgl3dq5jwc0000gn/T/ipykernel_25976/3772038928.py\", line 135, in forward\n",
      "    out = self.layer3(out)\n",
      "          ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/jh/p1jvq4k96b78klmgl3dq5jwc0000gn/T/ipykernel_25976/3772038928.py\", line 70, in forward\n",
      "    out = F.relu(self.bn1(self.conv1(x)))\n",
      "                          ^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 460, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/executing/executing.py\", line 317, in executing\n",
      "    args = executing_cache[key]\n",
      "           ~~~~~~~~~~~~~~~^^^^^\n",
      "KeyError: (<code object forward at 0x115e94c30, file \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 459>, 4662578224, 64)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1160, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/stack_data/core.py\", line 565, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/stack_data/utils.py\", line 84, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/stack_data/core.py\", line 555, in mapper\n",
      "    return cls(f, options)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/stack_data/core.py\", line 520, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/executing/executing.py\", line 369, in executing\n",
      "    args = find(source=cls.for_frame(frame), retry_cache=True)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/executing/executing.py\", line 252, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/executing/executing.py\", line 270, in for_filename\n",
      "    result = source_cache[filename] = cls._for_filename_and_lines(filename, lines)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/executing/executing.py\", line 281, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "                                               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/stack_data/core.py\", line 79, in __init__\n",
      "    super(Source, self).__init__(*args, **kwargs)\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/site-packages/executing/executing.py\", line 228, in __init__\n",
      "    self.tree = ast.parse(ast_text, filename=filename)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/autumnstar/opt/anaconda3/envs/Python_Tutorials/lib/python3.11/ast.py\", line 50, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "SystemError: AST constructor recursion depth mismatch (before=132, after=36)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  # Read Excel file and extract the labels for the training set\n",
    "  train_label_df = pd.read_excel('SampleDataset/trainlabel1.xlsx')\n",
    "  train_labels = train_label_df['target'].tolist()\n",
    "\n",
    "  # Read Excel file and extract the labels for the test set\n",
    "  test_label_df = pd.read_excel('SampleDataset/testlabel1.xlsx')\n",
    "  test_labels = test_label_df['target'].tolist()\n",
    "\n",
    "  # Check if GPU is available, otherwise use CPU\n",
    "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "  # Define data transformations for training and test sets\n",
    "  train_transform = transforms.Compose([\n",
    "      transforms.Resize((224, 224)),\n",
    "      transforms.RandomHorizontalFlip(),  # randomly flip the image horizontally\n",
    "      transforms.RandomRotation(10),  # randomly rotate the image by up to 10 degrees\n",
    "      transforms.ToTensor(),  # convert the image to a PyTorch tensor\n",
    "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "  ])\n",
    "  test_transform = transforms.Compose([\n",
    "      transforms.Resize((224, 224)),\n",
    "      transforms.RandomHorizontalFlip(),  # randomly flip the image horizontally\n",
    "      transforms.RandomRotation(10),  # randomly rotate the image by up to 10 degrees\n",
    "      transforms.ToTensor(),  # convert the image to a PyTorch tensor\n",
    "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "  ])\n",
    "\n",
    "  # Create custom datasets for training and test sets\n",
    "  train_dataset = CustomDataset(root_dir='SampleDataset/trainset', targets=train_labels, transform=train_transform)\n",
    "  test_dataset = CustomDataset(root_dir='SampleDataset/testset', targets=test_labels, transform=test_transform)\n",
    "\n",
    "  # Create data loaders to load the data in batches\n",
    "  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=8)\n",
    "  test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=8)\n",
    "\n",
    "  # This class defines a single residual block within the ResNet architecture.\n",
    "  # Residual blocks are the key building blocks of ResNet and help mitigate the vanishing gradient problem by introducing shortcut connections.\n",
    "  # The class defines two convolutional layers, each followed by batch normalization and ReLU activation.\n",
    "  # The shortcut connection handles the residual mapping when the input and output dimensions are different due to stride changes.\n",
    "  class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "      super(ResidualBlock, self).__init__()\n",
    "\n",
    "      # First convolutional layer with optional stride\n",
    "      self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "      self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "      # Second convolutional layer\n",
    "      self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "      self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "      # Shortcut connection for the residual\n",
    "      self.shortcut = nn.Sequential()\n",
    "      if stride != 1 or in_channels != out_channels:\n",
    "          self.shortcut = nn.Sequential(\n",
    "              nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "              nn.BatchNorm2d(out_channels)\n",
    "          )\n",
    "\n",
    "      # Initialize weights using Kaiming initialization\n",
    "      for m in self.modules():\n",
    "          if isinstance(m, nn.Conv2d):\n",
    "              init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "      residual = x\n",
    "\n",
    "      # First convolutional layer followed by batch normalization and ReLU\n",
    "      out = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "      # Second convolutional layer followed by batch normalization\n",
    "      out = self.bn2(self.conv2(out))\n",
    "\n",
    "      # Add the shortcut connection to the residual\n",
    "      out += self.shortcut(residual)\n",
    "\n",
    "      # Apply ReLU activation\n",
    "      out = F.relu(out)\n",
    "      return out\n",
    "\n",
    "\n",
    "  # This class defines the complete Residual Neural Network (ResNet) architecture for regression tasks.\n",
    "  # It includes the initial convolutional layer, multiple stages of residual blocks, global average pooling, and a fully connected layer for regression output.\n",
    "  # The method implements the forward pass of the entire ResNet architecture.\n",
    "  # It applies each layer sequentially, from the initial convolutional layer to the fully connected output layer.\n",
    "  # The global average pooling operation is used to reduce the spatial dimensions before the final regression prediction.\n",
    "  class ResNet(nn.Module):\n",
    "    def __init__(self, num_layers=2, num_channels=64, num_classes=1):\n",
    "      super(ResNet, self).__init__()\n",
    "\n",
    "      # Initialize the number of input channels for the first convolutional layer\n",
    "      self.in_channels = num_channels\n",
    "\n",
    "      # First convolutional layer\n",
    "      self.conv1 = nn.Conv2d(3, num_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "      self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "\n",
    "      # Create layers for each stage of the network using the make_layer method\n",
    "      self.layer1 = self.make_layer(64, num_layers)\n",
    "      self.layer2 = self.make_layer(128, num_layers, stride=2)\n",
    "      self.layer3 = self.make_layer(256, num_layers, stride=2)\n",
    "      self.layer4 = self.make_layer(512, num_layers, stride=2)\n",
    "\n",
    "      # Global average pooling and fully connected layer for classification/regression\n",
    "      self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "      self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "      # Initialize weights using Kaiming initialization for convolutional layers\n",
    "      for m in self.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "          init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def make_layer(self, out_channels, num_blocks, stride=1):\n",
    "      layers = []\n",
    "\n",
    "      # Create the first residual block for each stage with a possible stride\n",
    "      layers.append(ResidualBlock(self.in_channels, out_channels, stride))\n",
    "      self.in_channels = out_channels\n",
    "\n",
    "      # Create additional residual blocks for the stage\n",
    "      for _ in range(1, num_blocks):\n",
    "        layers.append(ResidualBlock(out_channels, out_channels))\n",
    "\n",
    "      # Construct a sequential container with the layers\n",
    "      return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "      # Apply the initial convolutional layer followed by batch normalization and ReLU\n",
    "      out = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "      # Pass through each stage of the network\n",
    "      out = self.layer1(out)\n",
    "      out = self.layer2(out)\n",
    "      out = self.layer3(out)\n",
    "      out = self.layer4(out)\n",
    "\n",
    "      # Apply global average pooling to reduce spatial dimensions to 1x1\n",
    "      out = self.avg_pool(out)\n",
    "\n",
    "      # Reshape the tensor and apply the fully connected layer\n",
    "      out = out.view(out.size(0), -1)\n",
    "      out = self.fc(out)\n",
    "      return out\n",
    "\n",
    "  # Initialize the ResNet model\n",
    "  net = ResNet().to(device)\n",
    "\n",
    "  # Define the loss function and optimizer\n",
    "  criterion = nn.L1Loss()\n",
    "  optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "  # Train the model using the trainloop function\n",
    "  trainloop(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MpN512VupHDf",
    "ExecuteTime": {
     "start_time": "2023-11-24T22:23:57.438253Z"
    }
   },
   "outputs": [],
   "source": [
    "def r_squared(y_pred, y_true):\n",
    "  # Calculate the total sum of squares and the residual sum of squares\n",
    "  total_sum_of_squares = torch.sum((y_true - torch.mean(y_true)) ** 2)\n",
    "  residual_sum_of_squares = torch.sum((y_true - y_pred) ** 2)\n",
    "\n",
    "  # Calculate the R-squared value\n",
    "  r2 = 1 - (residual_sum_of_squares / total_sum_of_squares)\n",
    "\n",
    "  return r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dgmLDjx6pvj1",
    "ExecuteTime": {
     "start_time": "2023-11-24T22:22:53.786103Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the network to evaluation mode\n",
    "net.eval()\n",
    "\n",
    "# Initialize empty lists to store true and predicted labels\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Use torch.no_grad() to disable gradient calculation during testing\n",
    "with torch.no_grad():\n",
    "  # Iterate over the test data\n",
    "  for inputs, labels in test_loader:\n",
    "    # Move input data and labels to the specified device and convert to float tensors\n",
    "    inputs = inputs.to(device).float()\n",
    "    labels = labels.to(device).float()\n",
    "\n",
    "    # Perform a forward pass through the network to get predicted outputs\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    # Append true labels and predicted labels to their respective lists\n",
    "    true_labels += labels.tolist()\n",
    "    predicted_labels += outputs.squeeze().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-tXKUDLUp11Z",
    "ExecuteTime": {
     "end_time": "2023-11-24T22:22:53.788647Z",
     "start_time": "2023-11-24T22:22:53.787909Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code block calculates and prints three regression evaluation metrics:\n",
    "\n",
    "1. Mean Absolute Error (MAE):\n",
    "The average absolute difference between the predicted and true labels.\n",
    "\n",
    "2. Mean Squared Error (MSE):\n",
    "The average of the squared differences between predicted and true labels.\n",
    "\n",
    "3. R-squared (R^2):\n",
    "The proportion of variance in the dependent variable that is explained by the independent variable(s).\n",
    "\n",
    "\"\"\"\n",
    "# Convert the predicted_labels and true_labels lists to PyTorch tensors\n",
    "predicted_labels = torch.tensor(predicted_labels)\n",
    "true_labels = torch.tensor(true_labels)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(true_labels, predicted_labels)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(true_labels, predicted_labels)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Calculate R-squared (R^2)\n",
    "r2 = r_squared(predicted_labels, true_labels)\n",
    "print(\"R-squared (R^2):\", r2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXo3VnvvqmDL",
    "ExecuteTime": {
     "start_time": "2023-11-24T22:22:53.790046Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code block generates plots for visualizing the model's performance:\n",
    "\n",
    "1. Training Loss Curve:\n",
    "Plots the loss values over iterations during training.\n",
    "It helps visualize the convergence and progress of the training process.\n",
    "\n",
    "2. Model Prediction Residuals:\n",
    "Creates a scatter plot of true labels against residuals (differences between true and predicted labels).\n",
    "This plot helps analyze the distribution and patterns of prediction errors.\n",
    "\n",
    "3. Regression Line:\n",
    "Calculates and plots the regression line by fitting a linear regression model to the true and\n",
    "predicted labels.\n",
    "This helps visualize how well the predicted labels align with the true labels.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Calculate the residuals as the difference between true_labels and predicted_labels\n",
    "residuals = np.array(true_labels) - np.array(predicted_labels)\n",
    "\n",
    "# Plot the training loss curve\n",
    "plt.plot(loss_list)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.show()\n",
    "\n",
    "# Plot the residuals\n",
    "plt.scatter(true_labels, residuals, s=5)\n",
    "plt.xlabel('True Labels')\n",
    "plt.ylabel('Prediction Residuals')\n",
    "plt.title('Model Prediction Residuals')\n",
    "plt.show()\n",
    "\n",
    "# Calculate and plot regression line\n",
    "regression_line = np.polyfit(true_labels, predicted_labels, 1)\n",
    "regression_line_fn = np.poly1d(regression_line)\n",
    "plt.scatter(true_labels, predicted_labels, s=5)\n",
    "plt.plot(true_labels, regression_line_fn(true_labels), color='red')\n",
    "plt.xlabel('True Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Regression Line')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
